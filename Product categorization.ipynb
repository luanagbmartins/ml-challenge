{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "from nltk import FreqDist\n",
    "from gensim import corpora\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import gc\n",
    "from joblib import dump, load\n",
    "\n",
    "import plotly_express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'data/train.csv'\n",
    "data_train = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hidrolavadora Lavor One 120 Bar 1700w  Bomba A...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>ELECTRIC_PRESSURE_WASHERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Placa De Sonido - Behringer Umc22</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>SOUND_CARDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maquina De Lavar Electrolux 12 Kilos</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>WASHING_MACHINES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Par Disco De Freio Diant Vent Gol 8v 08/ Frema...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>VEHICLE_BRAKE_DISCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flashes Led Pesta単as Luminoso Falso Pesta単as P...</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>spanish</td>\n",
       "      <td>FALSE_EYELASHES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title label_quality  \\\n",
       "0  Hidrolavadora Lavor One 120 Bar 1700w  Bomba A...    unreliable   \n",
       "1                  Placa De Sonido - Behringer Umc22    unreliable   \n",
       "2               Maquina De Lavar Electrolux 12 Kilos    unreliable   \n",
       "3  Par Disco De Freio Diant Vent Gol 8v 08/ Frema...    unreliable   \n",
       "4  Flashes Led Pesta単as Luminoso Falso Pesta単as P...    unreliable   \n",
       "\n",
       "     language                   category  \n",
       "0     spanish  ELECTRIC_PRESSURE_WASHERS  \n",
       "1     spanish                SOUND_CARDS  \n",
       "2  portuguese           WASHING_MACHINES  \n",
       "3  portuguese        VEHICLE_BRAKE_DISCS  \n",
       "4     spanish            FALSE_EYELASHES  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train.describe().iloc[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pt = data_train.loc[data_train['language'] == 'portuguese']\n",
    "del data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pt.drop(columns='label_quality')\n",
    "data_pt.drop_duplicates(subset =\"title\", \n",
    "                           keep = False,\n",
    "                           inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pt['title'] = data_pt['title'].str.replace(\"[^a-zA-Z#]\", \"\")\n",
    "data_pt['title'] = data_pt['title'].str.replace(\"#[a-zA-Z]\", \"\")\n",
    "data_pt['title'] = data_pt['title'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>2]))\n",
    "data_pt['title'] = data_pt['title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_pt = data_pt['category']\n",
    "data_pt = data_pt['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_pt.to_csv(r'category_pt.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(rev, stop_words):\n",
    "    rev_new = \" \".join([i for i in rev if i not in stop_words])\n",
    "    return rev_new\n",
    "\n",
    "stopwords = get_stop_words('portuguese')\n",
    "data_pt = [remove_stopwords(r.split(), stopwords) for r in data_pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_words(x, terms = 40):\n",
    "    all_words = ' '.join([text for text in x])\n",
    "    all_words = all_words.split()\n",
    "\n",
    "    fdist = FreqDist(all_words)\n",
    "    words_df = pd.DataFrame({'word':list(fdist.keys()), 'count':list(fdist.values())})\n",
    "\n",
    "    # selecting top 20 most frequent words\n",
    "    # data = words_df.nsmallest(columns='count', n=terms) \n",
    "    data = words_df.nlargest(columns='count', n=terms)\n",
    "    fig = px.bar(data, x = \"word\", y = \"count\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq_words(data_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pt = pd.Series(data_pt).apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter extremes removes all tokens in the dictionary that are:\n",
    "\n",
    "Less frequent than no_below documents (absolute number, e.g. 5) or\n",
    "More frequent than no_above documents (fraction of the total corpus size, e.g. 0.3).\n",
    "After (1) and (2), keep only the first keep_n most frequent tokens (or keep all if keep_n=None)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(data_pt)\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.8)\n",
    "dictionary.save_as_text('dictionary')\n",
    "#del dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luana/miniconda3/envs/IA/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning:\n",
      "\n",
      "The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data_pt.to_csv(r'data_pt.csv', index=False, header=False)\n",
    "# del data_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix = [dictionary.doc2bow(rev) for rev in data_pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = TfidfTransformer().fit_transform(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_category = pd.read_csv('category_pt')\n",
    "clf = MultinomialNB().fit(xTrain, loaded_category.index.values.astype(int))\n",
    "dump(clf, 'model.joblib') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
